---
title             : "Bayesian sampling in the interpretation of quantifiers? Evidence from Markov chain Monte Carlo with People"
shorttitle        : "Markov chain Monte Carlo with People"

author: 
  - name          : "Fabian Dablander"
    affiliation   : "1"
    corresponding : yes
    email         : "dablander.fabian@gmail.com"

affiliation:
  - id            : "1"
    institution   : "University of Tübingen"

author_note:    |
    This research was conducted during an internship supervised by Dr. phil Michael Franke at the University of Tübingen. Most of the ideas presented here are his. I want to thank him for his creative input and patience.

keywords          : "Bayesian modeling, experimental pragmatics, quantifier interpretation, Markov chain Monte Carlo with People"

abstract:  |
   How do people use quantifiers such as *some* and *many*? Within the growing discipline of probabilistic pragmatics, we take first steps in answering this question by comparing three Bayesian models that estimate participants' subjective probability distribution of ten different quantifiers. We use an experimental design in which participants' responses are viewed as states in a Markov chain Monte Carlo algorithm---"Markov chain Monte Carlo with People" [@sanborn2007markov]. Fourty-five participants were presented with fifty forced-choice trials for four different, randomly chosen quantifiers in which two images were presented which displayed different numbers of red dots. Participants had to indicate which image was a better description for the specific quantifier in use. Three models of the data generating process were developed. Interestingly, the model which closely mirrors the experimental design and assumes participants are Bayesian samplers had higher prediction error than a model which assumes participants soft-max prefer the number which is closer to the mode of the subjective probability distribution. Limitations of our preliminary finding as well as implications for further research are discussed. 
   
wordcount         : 2554
bibliography      : ["r-references.bib", "bibliography.bib"]

figsintext        : yes
figurelist        : no
tablelist         : no
footnotelist      : no
lineno            : no

lang              : "english"
class             : "man"
output:
  papaja::apa6_pdf:
    includes:
      in_header: "header.tex"
      after_body: "appendix.tex"
---

```{r, echo = FALSE}
knitr::opts_chunk$set(message = FALSE, echo = FALSE, warning = FALSE)
```

```{r}
library('dplyr')
library('papaja')
library('ggmcmc')
library('stringr')
library('ggplot2')
source('../exploring/prepare_exploring.R')

# load the data
dat = read.csv('../data/cleaned_data.csv')

# based on visual inspection of the traceplots, these participants were removed
to_remove = read.csv('../exploring/ids.csv') %>% filter(number %in% c(10, 11, 15, 22, 34))
dat = filter(dat, !(id %in% to_remove$id)) %>% 
  mutate(language = as.factor(str_to_lower(language))) %>% tbl_df
```


How do people interpret quantifiers? Say I arrive hungry at a party where I gleefully discover twelve cookies on the kitchen table. The host, recognising my desire, says that I can have *some*. Can I eat two? Sure. What about ten? Probably not.

Why does two seem more likely than ten? Following the data-oriented approach of probabilistic pragmatics [@franke2016probabilistic], we tackle this question by estimating the subjective probability distribution over possible values (in the above example: cookies) for different quantifiers. To arrive at this distribution, we utilize an experimental design which uses participants' answers as states in a Markov chain Monte Carlo (MCMC) algorithm---"Markov chain Monte Carlo with People" [@sanborn2007markov]. Additionally, we develope three Bayesian models of the data generating process, and directly test the hypothesis of a 'Bayesian brain' [@sanborn2016bayesian] in quantifier use. Let's unpack the underlying ideas in turn.

### Bayesian inference
Bayesian approaches are becoming increasingly popular as (a) an alternative to classical statistical data analysis [@wagenmakers2015need], (b) a tool to estimate (hierarchical) cognitive models [@lee2011cognitive], and (c) a theory about how the brain works [@sanborn2016bayesian]. The latter idea is known as the 'Bayesian brain', a theme that offers to unify different aspects of cognition [@chater2010bayesian]; the brain is viewed as a Bayesian inference machine which approximates complex probability distributions.

The most common objection to this idea is the observation that human cognition seems far from *optimal* or *rational* [@marcus2013robust; @marcus2009kluge]; instead, it seems more plausible to assume that our actions are guided by evolved satisficing strategies that lead to common reasoning errors such as the conjunction fallacy [e.g., @tversky1983extensional]. In a recent paper, however, @sanborn2016bayesian explain these satisficing strategies and the resulting reasoning errors by viewing the brain not as an ideal Bayesian reasoner, but as Bayesian sampler. Only asymptotically do we follow the rules of probability exactly and act according to rational choice; with finite time and, thus, finite samples, reasoning errors result.

In this paper, we seek to directly test the notion that participants are Bayesian samplers in the domain of quantifier interpretation. We utilize an experimental design---'Markov chain Monte Carlo with People' [@sanborn2007markov]---which is inspired by computational challenges of Bayesian inference, and which allows us to sample from the subjective probability distribution of quantifiers.

Bayesian inference starts with a prior belief $p(\theta)$ over some parameter vector $\theta$. The likelihood function $\mathcal{L}(\theta|\textbf{y})$ specifies how the parameter vector relates to the observed data $\textbf{y}$. Combining the two using Bayes' rule two yields the posterior distribution over the parameter vector, $p(\theta|\textbf{y})$:

$$
p(\theta|\textbf{y}) = \frac{p(\theta)\mathcal{L}(\theta|\textbf{y})}{\int p(\theta)\mathcal{L}(\theta|\textbf{y})\mathrm{d}\theta}
$$

In most cases, the denominator is a high dimensional integral which cannot be calculated analytically. To this end, sampling-based methods such as Markov chain Monte Carlo techniques are used which avoid computing the integral altogether [for an introduction, see e.g., @ravenzwaaij2016simple]. Concretely, one sets up a Markov chain which has as its stationary distribution the normalized posterior distribution $p(\theta|\textbf{y})$. Various algorithms have been proposed, but the canonical one is the Metropolis-Hastings (MH) method [@metropolis1953equation; @hastings1970monte].


### Metropolis-Hastings
The key insight here is that we do not need to have access to the posterior distribution but need only be able to compute its density, $\pi(x)$, for values of $x$. The MH algorithm works as follows (see also the pseudocode below). Start at random initial state $x$. In each step, generate a new sample $x^{\star}$ based on the current value using a proposal function. Choose $x^{\star}$ over $x$ using a specified acceptance function. Required some mathematical conditions [see e.g., @jackman2009bayesian, pp. 201], this constitutes a Markov chain of first order which has $p(\theta|\textbf{y})$ as its stationary distribution. Once the stationary distribution is reached, the generated samples are equivalent to samples from $p(\theta|\textbf{y})$. The samples before that time in point are discarded as 'burn-in'.

If we further assume that the probability of proposing a new state $x^{\star}$ based on the current state $x$ is the same as the probability of proposing $x$ based on $x^{\star}$, i.e., the proposal distribution is symmetric, we can use the Barker acceptance function [@barker1965monte]

$$
A(x; x^{\star}) = \frac{\pi(x^{\star})}{\pi(x^{\star}) + \pi(x)}
$$

where $\pi(x)$ indicates the density of the value $x$ under the posterior distribution.

\begin{spacing}{0.8}
\begin{algorithm}[ht]
    \caption{Barker Random-Walk Metropolis-Hasting}
    
    \begin{algorithmic}
    
        \Procedure{Metropolis}{$\sigma, N$}
          \State $\mbox{samples[1]} \gets \mbox{RandomState()}$
          \State $\mbox{samples[2:N]} \gets 0$
          \For{$i = 2$ to $N$}
              \State $x \gets \mbox{samples[i - 1]}$
              \State $x^{\star} \gets x + \mbox{Normal(}\mu = 0, \sigma = \sigma\mbox{)}$
              \State $A \gets \frac{\pi(x^{\star})}{\pi(x^{\star}) + \pi(x)}$
              
              \If{$A \geq \mbox{Uniform(0, 1)}$}
                  \State $\mbox{samples[i]} \gets x^{\star}$
              \Else
                  \State $\mbox{samples[i]} \gets x$
              \EndIf
              
          \EndFor
          
      \State \textbf{return} samples
      
      \EndProcedure
    \end{algorithmic}
\end{algorithm}
\end{spacing}

```{r, eval = FALSE}
# we want to sample from a t distribution with df = 2
metropolis <- function(n_samples = 100000) {
  res <- rep(NA, n_samples)
  res[1] <- rnorm(1)
  
  for (i in seq(from = 2, to = n_samples)) {
    prev <- res[i-1]
    cur <- prev + rnorm(1, mean = 0, sd = .1)
    
    A <- dt(cur, df = 2) / (dt(cur, df = 2) + dt(prev, df = 2))
    res[i] <- ifelse(A > runif(1), cur, prev)
  }
  
  res
}
```

In our experimental design we use participants' responses as states in a Markov chain, with the stationary distribution being the subjective probability distribution over values provided a specific quantifier. We then estimate three models of the data generating process. One of them, referred to as the Barker model, describes the experimental design. If participants are Bayesian samplers, this model should describe the data best.

The document was written in a reproducible manner using Rmarkdown and the papaja R package [@R-papaja]. All materials, including data, code for the experiment and data analysis, and manuscript, can be found at \mbox{\href{https://github.com/fdabl/MCMCP}{https://github.com/fdabl/MCMCP}}.


# Methods
We report how we determined our sample size, all data exclusions, all manipulations, and all measures in the study. <!-- 21-word solution (Simmons, Nelson & Simonsohn, 2012; retrieved from http://ssrn.com/abstract=2160588) --> In a pilot study, five participants were recruited in order to test the technical setup of the experiment. Those participants are not included in the final analysis.

## Participants
Fifty participants were recruited from Amazon Mechanical Turk [@buhrmester2011amazon]. After inspection of the data, five participants were removed\footnote{See appendix for the rationale and the excluded participants' data patterns.}, leaving a total of fourty-five participants. On average, the experiment took 9.38 minutes to complete. The experiment seemed to be engaging and not too difficult (Mean engagement = 7.35, Mean difficulty = 3.73; scale: 1-10). Fourty-two Participants were self-reported native English speakers, three were of different mother tongue (French, Romanian, Russian).

```{r, eval = FALSE}
mean(dat$time / 60000) # completion time (not quite true) # FIX THIS
table(dat$language) / 160 # distribution of language
```

## Material
Images of random dot patterns were used. Each image showed 432 dots, of which any amount could be coloured red. The other dots were coloured black. For each possible pattern (0 - 432 red dots), ten images were generated. On each trial, images were randomly chosen out of the generated pool of images.

## Procedure
After reading the instruction, each participant went through four blocks of 50 trials each. Each block consisted of a quantifier randomly chosen out of *Half*, *About half*, *Less than half*, *Few*, *Very few*, *Many*, *Most*, *The majority*, *Some*, *Almost all*. No participant saw a quantifier twice, and *About half* was never followed by *Half* and *Very few* never by *Few* (and vice versa). On each trial, the participant had to choose which of the two images fitted the description best (see Figure 1 for an example trial). On the following trial, new images were generated.

![Example Trial. Participants had to choose between the left or right image. Names in the description were chosen randomly out of a pool of fifty names.](img/trial-image)

Analogously to the steps of a MH algorithm, the number of red dots in the images on the first trial of each block were generated randomly. On subsequent trials, samples based on the current number of red dots were proposed. Note that the support of the distribution we want to elicit is bounded by the interval $[0, 432]$. Therefore, to ensure a symmetric proposal function, our MH algorithm proceeded as follows.
Given the chosen number of red dots $x$, uniformly generate points for the second image within the interval $[x - \delta, x + \delta]$ with probability $1 - \epsilon$. With probability $\epsilon$, points were generated uniformly outside the interval. Again, symmetry is crucial to enable the use of the Barker acceptance function. We set $\delta = 20$ and $\epsilon = .4$.

As an example, assume the participant chose the image with 420 red dots. Out of a hundred cases, in sixty cases the newly selected image will have points from the set $\{400, \ldots, 432, 0, \ldots, 8\}$. In fourty cases, it will have points selected from the set $\{8, \ldots, 400\}$.

```{r, fig.height=16, fig.width = 14, fig.cap="Histograms of the raw data (number chosen) for all quantifiers pooled over participants."}
ggplot(dat, aes(x = number_chosen)) +
  geom_histogram(bins = 20) +
  facet_wrap(~ quantifier) +
  theme_bw() +
  xlab('Number chosen') +
  ggtitle('Raw data of number chosen') +
  theme(plot.title = element_text(size = 24),
        axis.title = element_text(size = 22))
```


# Data analysis
All analyses were completed using the open-source statistical programming language R [@R-base]. We removed five participants whose response pattern was highly unusual (see appendix). The data we want to explain is the choice the participants make in each trial: do they pick the image with the higher number of red dots? Figure 2 shows a visualization of pooled participants' data for all quantifiers. See Figure 3 for a visualization of participant-wise choice data for the quantifier *Some*. The full dataset can be interactively explored at \mbox{\href{https://fdabl.shinyapps.io/MCMCP/}{https://fdabl.shinyapps.io/MCMCP/}}.

```{r, fig.height=16, fig.width = 14, fig.cap="Shows the raw data of all participants who completed a block with the quantifier *Some*. Colour indicates the predictions of the Distance model for each respective data point. Blue line indicates the mode of the subjective distribution. Note that the first ten trials were discarded as burn-in."}
test = melt_data(d, 'Some', what = 'quantifier') %>%
  mutate(Predictions = ifelse(chose_higher, pred_distance, 1 - pred_distance),
         mode = mode_distance)

p = ggplot(test, aes(x = trial, y = value)) +
      geom_point(aes(color = Predictions), size = 3) +
      scale_colour_continuous(low = 'red', high = 'green', limits = c(0, 1)) +
    
      #geom_text(aes(x = trial, label = round(predictions, 2))) +
      geom_path(data = filter(test, choice == 'number_chosen'), size = 1.2) +
      xlab('Trial') + ylab('Number') +
      geom_hline(yintercept = c(108, 216, 324, 432), linetype = 'dotted') +
      geom_hline(aes(yintercept = mode), color = 'blue') +
      scale_y_continuous(breaks = scales::pretty_breaks(n = 15),
                         limits = c(0, 432)) + theme_bw() +
      ggtitle('Choice data for Quantifier "Some" and Distance model predictions') +
      theme(plot.title = element_text(size = 24),
            axis.title = element_text(size = 22))

all_ids = unique(d$id)
test_ids = unique(test$id)
labels = as.list(sapply(test_ids, function(id) which(id == all_ids)))

labeller = function(variable, value) {
    value = droplevels(value)
    labels[value]
}

p + facet_wrap(~ id, ncol = 3, labeller = labeller)
```


## Model specification
![Graphical model specification for the Barker model (top), the Distance model (left), and the Closer model (right). Transparent nodes indicate parameters, shaded ones indicate observed values. Circles indicate continuous, rectangles categorical values. Nodes with double lines indicate deterministic nodes.](model_graphs/models_combined.png)

We developed three models of the data generating process. Common to all is the parameterization of the distribution over number of red dots for each quantifier as a beta-binomial distribution, and the Bernoulli likelihood function.

Two of the models, thereafter *Closer model* and *Distance model*, assume the participant is soft-max preferring the image in which the number of red dots is closer to the mode of the subjective distribution for that quantifier. The Distance model uses information about the distance of the choices to the mode, while the Closer model uses a categorical measure of distance (closer or not closer). The models are similar to the one discussed by @franke2016cogsci for the *bin comparison* task.

The third model, which we call the *Barker model*, does not use the mode but instead compares the likelihood of the respective number of red dots---just like the Barker acceptance function in the MCMC algorithm. See Figure 4 for the graphical model specifications using the notation of @lee2014bayesian.


## Model inference
We used JAGS [@plummer2003jags] to estimate the model parameters. 100.000 samples were obtained from two chains with a thinning rate of 2 after burn-in of 5000 that ensured convergence according to $\hat R$ [@gelman1992inference] for the Distance and Closer model. Even after increasing the samples to 200.000, the Barker model did not converge. This was because the parameters were underspecified; different values for $a$, $b$, and $c$ resulted in the same likelihood. Therefore, we set the parameter $c = 1$ which resulted in convergence\footnote{Changing the parameter to c = .2 or c = .5 did not alter the main conclusion drawn. However, the model fitted best with $c = .2$; we report conclusions based on this fit.}.


# Results and Discussion
We compared the models using the likelihood as well as the Deviance Information Criterion [DIC; @spiegelhalter2002bayesian], the latter being an estimate for out of sample prediction error. The Distance model had lower prediction error than the Closer model (see Table 1). This is not surprising, because the Distance model uses information about the numerical distance of the choices to the mode, while the Closer model only cares about which choice is closer. Interestingly, the Distance model fares better than the Barker model. Note again that the Barker model closely mirrors the experimental design.

```{r}
namess = c('Barker', 'Distance', 'Closer')
DIC = sort(setNames(c(params_barker$dic, params_distance$dic, params_closer$dic), namess))
Likelihood = select(d, pred_barker, pred_distance, pred_closer) %>% 
  apply(., 2, sum) %>% 
  setNames(., namess) %>% 
  sort(., decreasing = TRUE)
```

```{r, results = 'asis'}
apa_table(
  data.frame(rbind(DIC, Likelihood)),
  caption = 'Results of model comparison.'
)
```

The underspecification of parameters with $c$ as a free parameter in the Barker model required us to specify contraints. We did this by fixing $c$; $c$ influences how strongly participants prefer higher values. For $c$ approaching zero, participants have no preference, i.e. there choice whether to prefer the image with the higher number of red dots or the image with the lower number of red dots was random; for $c$ greater than one, participants prefer higher values. The prediction error as measured by the DIC decreased with a decreasing $c$, indicating that the Barker model did not capture relevant regularities in the data.

Although we want to avoid drawing strong conclusions from these preliminary results, it seems that, in contrast to what the 'Bayesian brain' hypothesis postulates, participants do not engage in sampling-based algorithmic behaviour in the domain of quantifier interpretation. Instead, it seems that participants infer likely values given the quantifier based on the distance to the mode of the subjective distribution over all values under that quantifier.

```{r, eval = FALSE}
# plot the posterior distribution over quantifiers implied by a and b from the Distance model
# or not?
mean_dist = d %>%
  select(a_distance, b_distance, quantifier) %>% 
  group_by(quantifier) %>% 
  summarize(a = mean(a_distance), b = mean(b_distance))

N = 10000
res = apply(mean_dist, 1, function(row) {
  a = as.numeric(row[2])
  b = as.numeric(row[3])
  quantifier = row[1]
  
  data = rbetabinom.ab(n = N, size = 432, shape1 = a, shape2 = b)
  data.frame(quantifier = rep(quantifier, N), number_chosen = data)
})

dd = d %>% 
  select(number_chosen, quantifier) %>% 
  mutate(data = 'empirical')

dat = tbl_df(do.call('rbind', res)) %>%
  mutate(data = 'predicted')

plot_d = rbind(dd, dat)

 ggplot(plot_d, aes(x = number_chosen,
   y = ..count.. / sum(..count..), fill = data)) +
   geom_histogram(alpha = 1/2, position = 'identity') +
   facet_wrap(~ quantifier)
```

There are a number of limitations that need to be addressed. With respect to the experimental design, it is unclear how many trials are needed for the Markov chain to converge, and for the resulting samples to be draws from the subjective probability distribution. In our analysis, we excluded the first ten trials as burn-in, only working with the resulting fourty. Other choices might be equally, or more reasonable. This point is exaggerated by the observation that participant's choices are---by design---not independent; there is serial autocorrelation which violates our assumption of an independent Bernoulli likelihood.
Along the same lines, it is unclear whether our parameter settings $\delta = 20$ and $\epsilon = .4$ for the proposal function which generated new images are adequate, i.e. whether this results in a good exploration of the state space.

However, these issues are analogous to the issues in Markov chain Monte Carlo based inference more broadly, an area where remedies have already been developed; future research should utilize approaches from this domain. For example, to assess convergence, one could repeatedly present the participants with blocks of the same quantifier, i.e. run more than one Markov chain, and compute statistics such as $\hat R$ [@gelman1992inference].

In this paper, we assumed that participants share the same probability distribution over the number of red dots for each quantifier; this simplifying assumption need not be reasonable. Future research should utilize a hierarchical approach similar to @franke2016cogsci, estimating individual-level probability distribution as variations of a shared population-level belief.

Despite the limitations, we believe that this paper constitutes a novel contribution by extending the use of Markov chain Monte Carlo with People type experiments to the domain of language interpretation. Moreover, it casts initial doubt on the idea of the brain as a Bayesian sampler in quantifier interpretation. Avenues for future research abound.

```{r render_appendix, include = FALSE}
papaja::render_appendix("appendix.Rmd")
```

# References
```{r create_r-references}
r_refs(file = "r-references.bib")
```

\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}